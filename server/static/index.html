<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Voice Live Agent Demo</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: #f0f4f8;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      color: #333;
      text-align: center;
    }

    h1 {
      font-size: 2rem;
      margin-bottom: 1.2rem;
    }

    .subtitle {
      font-size: 1rem;
      color: #555;
      margin-bottom: 2rem;
    }

    .controls {
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
      justify-content: center;
    }

    button {
      padding: 0.85rem 1.75rem;
      font-size: 1.05rem;
      border: none;
      border-radius: 0.5rem;
      cursor: pointer;
      transition: background 0.3s ease;
    }

    #startBtn {
      background-color: #0078d4;
      color: white;
    }

    #startBtn:hover {
      background-color: #005ea0;
    }

    #stopBtn {
      background-color: #e81123;
      color: white;
    }

    #stopBtn:disabled {
      background-color: #f3b2b2;
      cursor: not-allowed;
    }

    audio {
      margin-top: 2rem;
      display: block;
    }

    footer {
      position: absolute;
      bottom: 1rem;
      font-size: 0.85rem;
      color: #666;
    }
  </style>
</head>
<body>
  <h1>üéôÔ∏èFarmacia24</h1>
  <div class="subtitle">Parla con il BOT della Farmacia. Clicca qui sotto per iniziare.</div>

  <div class="controls">
      <div id="chatContainer">
        <div id="chatHistory"></div>
        <div id="chatInputArea">
          <input type="text" id="chatInput" placeholder="Scrivi un messaggio..." autocomplete="off" />
          <button id="sendBtn" onclick="sendTextMessage()" title="Invia messaggio">
            <span aria-label="Invia" role="img">üì§</span>
          </button>
          <button id="micBtn" onclick="toggleMic()" title="Parla con il bot">
            <span aria-label="Microfono" role="img">üé§</span>
          </button>
        </div>
      </div>
  <button id="stopBtn" onclick="stopStreaming()" title="Ferma la conversazione">Ferma la conversazione</button>
      <audio id="ttsPlayer" autoplay></audio>
  </div>

  <audio id="ttsPlayer" autoplay></audio>

  <footer id="pageFooter">
    Powered by Azure Voice Live ‚Ä¢ Demo Mode
  </footer>

  <script>
  let mediaStream, source, processor, micWorkletNode, socket, textSocket;
  let audioContext = new AudioContext({ sampleRate: 24000 });
  let isMicActive = false;
  let workletNode;

    // Load the AudioWorkletProcessor
    async function loadAudioProcessor() {
      // Load playback worklet and microphone capture worklet
      await audioContext.audioWorklet.addModule('/static/audio-processor.js');
      // mic worklet is loaded but the node will be created when the microphone stream is available
      await audioContext.audioWorklet.addModule('/static/mic-processor.js');
      workletNode = new AudioWorkletNode(audioContext, 'audio-processor');
      workletNode.connect(audioContext.destination);
    }

    async function playAudio(arrayBuffer) {
      if (audioContext.state === 'suspended') await audioContext.resume();
      const int16 = new Int16Array(arrayBuffer);
      const float32 = new Float32Array(int16.length);
      for (let i = 0; i < int16.length; i++) {
        float32[i] = int16[i] / (int16[i] < 0 ? 0x8000 : 0x7FFF);
      }
      workletNode.port.postMessage({ pcm: float32 });
    }

    function stopPlayback() {
      if (workletNode) workletNode.port.postMessage({ clear: true });
    }

    function float32ToInt16(float32Array) {
      const int16 = new Int16Array(float32Array.length);
      for (let i = 0; i < float32Array.length; i++) {
        const s = Math.max(-1, Math.min(1, float32Array[i]));
        int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
      }
      return int16;
    }

    async function startMicrophone() {
      mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      source = audioContext.createMediaStreamSource(mediaStream);

      // Create an AudioWorkletNode for microphone capture. It has 1 input and 0 outputs.
      micWorkletNode = new AudioWorkletNode(audioContext, 'mic-processor', {
        numberOfInputs: 1,
        numberOfOutputs: 0,
        channelCount: 1
      });

      // Receive Float32 chunks from the worklet, convert to Int16 and forward to websocket
      micWorkletNode.port.onmessage = (e) => {
        const float32 = e.data && e.data.input;
        if (!float32) return;
        const pcm = float32ToInt16(float32);
        if (socket?.readyState === WebSocket.OPEN) {
          socket.send(pcm.buffer);
        }
      };

      // Connect the media source to the worklet (no output so it won't play back locally)
      source.connect(micWorkletNode);
    }

    function stopMicrophone() {
      if (micWorkletNode && typeof micWorkletNode.disconnect === "function") {
        try { micWorkletNode.port.postMessage({ clear: true }); } catch(e){}
        micWorkletNode.disconnect();
        micWorkletNode = null;
      }
      if (processor && typeof processor.disconnect === "function") {
        processor.disconnect();
        processor = null;
      }
      if (mediaStream && mediaStream.getTracks) {
        mediaStream.getTracks().forEach(t => t.stop());
        mediaStream = null;
      }
    }

    function stopStreaming() {
        stopPlayback();
        if (socket && socket.readyState === WebSocket.OPEN) {
          socket.send(JSON.stringify({ Kind: "StopAudio" }));
        }
        socket.close();
      }

    function sendTextMessage() {
      const input = document.getElementById("chatInput");
      const text = input.value.trim();
      if (text) {
        appendMessage("user", text);
        if (textSocket && textSocket.readyState === WebSocket.OPEN) {
          textSocket.send(text);
        }
        input.value = "";
      }
    }
    
    // Add this directly after the function above:
    document.getElementById("chatInput").addEventListener("keydown", function(e) {
      if (e.key === "Enter") {
        e.preventDefault();
        sendTextMessage();
      }
    });

    function appendMessage(sender, text) {
      const chatHistory = document.getElementById("chatHistory");
      const msgDiv = document.createElement("div");
      msgDiv.className = sender === "user" ? "chatBubble userBubble" : "chatBubble botBubble";
      msgDiv.textContent = text;
      chatHistory.appendChild(msgDiv);
      chatHistory.scrollTop = chatHistory.scrollHeight;
    }

    function toggleMic() {
      if (!isMicActive) {
        startStreaming();
        isMicActive = true;
        document.getElementById("micBtn").classList.add("active");
      } else {
        stopStreaming();
        isMicActive = false;
        document.getElementById("micBtn").classList.remove("active");
      }
    }
    

    function startStreaming() {
      let wsProtocol = window.location.protocol === "https:" ? "wss" : "ws";
      let wsHost = window.location.host; 
      socket = new WebSocket(`${wsProtocol}://${wsHost}/web/ws`);
      console.log("Connecting to WebSocket:", socket.url);
      socket.binaryType = "arraybuffer";

      socket.onopen = async () => {
        console.log("WebSocket opened");
        await audioContext.resume();
        await startMicrophone();
        document.getElementById("stopBtn").disabled = false;
      };
      socket.onmessage = async (event) => {
        try {
          if (typeof event.data === "string") {
            const msg = JSON.parse(event.data);
            if (msg.Kind === "StopAudio") {
              stopPlayback();
            }
            if (msg.Kind === "Transcription") {
              // Voice transcription from backend
              appendMessage("user", msg.Text);
            }
            if (msg.Kind === "UserTranscription") {
              // Bot response to voice transcription
              appendMessage("bot", msg.Text);
            }
          } else if (event.data instanceof ArrayBuffer) {
            if (isMicActive) {
              try {
                await playAudio(event.data);
              } catch (e) {
                console.error("Failed to decode audio:", e);
              }
            }
          }
        } catch (err) {
          console.error("Error handling WebSocket message:", err, event);
        }
      }

      socket.onclose = () => {
        console.log("WebSocket closed");
        stopMicrophone();
        document.getElementById("stopBtn").disabled = true;
      };

      socket.onerror = (err) => console.error("WebSocket error", err);

      // Setup text websocket for chat
      textSocket = new WebSocket(`${wsProtocol}://${wsHost}/web/textws`);
      textSocket.onopen = () => {
        console.log("Text WebSocket opened");
      };
      textSocket.onmessage = (event) => {
        // Bot response to text message
        appendMessage("bot", event.data);
      };
      textSocket.onclose = () => {
        console.log("Text WebSocket closed");
      };
      textSocket.onerror = (err) => console.error("Text WebSocket error", err);
    }

    // Initialize the audio processor
    loadAudioProcessor();
  </script>
  <style>
    body {
      background: #ece5dd;
      font-family: 'Segoe UI', Arial, sans-serif;
      margin: 0;
      padding: 0;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
    }
    #chatContainer {
      background: #fff;
      border-radius: 10px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      width: 400px;
      max-width: 100vw;
      display: flex;
      flex-direction: column;
      height: calc(80vh - 40px);
      margin-bottom: 48px;
      overflow: hidden;
    }
    #chatHistory {
      flex: 1;
      overflow-y: auto;
      padding: 16px;
      display: flex;
      flex-direction: column;
      gap: 8px;
      background: #ece5dd;
    }
    .chatBubble {
      max-width: 70%;
      padding: 10px 16px;
      border-radius: 18px;
      font-size: 16px;
      word-break: break-word;
      margin-bottom: 2px;
      box-shadow: 0 1px 2px rgba(0,0,0,0.04);
      display: inline-block;
    }
    .userBubble {
      background: #25d366;
      color: #fff;
      align-self: flex-end;
      margin-left: auto;
      border: none;
    }
    .botBubble {
      background: #fff;
      color: #333;
      align-self: flex-start;
      margin-right: auto;
      border: 1px solid #e1e1e1;
    }
    #chatInputArea {
      display: flex;
      padding: 12px;
      background: #f7f7f7;
      border-top: 1px solid #e1e1e1;
      gap: 8px;
    }
    #chatInput {
      flex: 1;
      padding: 8px 12px;
      border-radius: 20px;
      border: 1px solid #e1e1e1;
      font-size: 16px;
      outline: none;
    }
    #sendBtn, #micBtn {
      background: #25d366;
      color: #fff;
      border: none;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      font-size: 18px;
      cursor: pointer;
      transition: background 0.2s;
    }
    #sendBtn:hover, #micBtn.active {
      background: #128c7e;
    }
    #stopBtn {
      margin: 12px auto;
      display: block;
      background: #f44336;
      color: #fff;
      border: none;
      border-radius: 20px;
      padding: 8px 24px;
      font-size: 16px;
      cursor: pointer;
    }
    #stopBtn:disabled {
      background: #e1e1e1;
      color: #888;
      cursor: not-allowed;
    }
    #pageFooter {
      position: fixed;
      left: 0;
      bottom: 0;
      width: 100vw;
      background: #ece5dd;
      color: #666;
      font-size: 0.85rem;
      text-align: center;
      padding: 8px 0;
      z-index: 10;
    }
  </style>
</body>
</html>
